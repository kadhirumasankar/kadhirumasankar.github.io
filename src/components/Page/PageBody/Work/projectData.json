[
  {
    "key": 1,
    "size": "small",
    "title": "Freshman Year",
    "date": "Fall 2017 - Spring 2018",
    "language": ["UT Austin", "#bb5826"],
    "imageUrl": "https://i.imgur.com/8onyBu4.jpg",
    "additionalText": "Classes taken:",
    "details": [
      "Differential Equations with Linear Algebra",
      "Statics",
      "Engineering Design Graphics",
      "Sequences, Series and Multivariable Calculus",
      "Intro to Computer Programming",
      "Principles of Chemistry I"
    ]
  },
  {
    "key": 2,
    "size": "small",
    "title": "Sophomore Year",
    "date": "Fall 2018 - Spring 2019",
    "language": ["UT Austin", "#bb5826"],
    "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Texas_Longhorns_logo.svg/1280px-Texas_Longhorns_logo.svg.png",
    "additionalText": "Classes taken:",
    "details": [
      "Spacecraft Dynamics",
      "Low-Speed Aerodynamics",
      "Mechanics of Solids",
      "Vector Calculus",
      "Dynamics",
      "Thermodynamics",
      "Engineering Computation",
      "Foundations of Accounting",
      "Engineering Communication"
    ]
  },
  {
    "key": 3,
    "size": "normal",
    "title": "ColorCube Class for UAVA",
    "date": "Spring 2019",
    "language": ["Python", "#fbbd08"],
    "githubUrl": "https://github.com/uavaustin/target-finder/blob/master/target_finder/color_cube.py",
    "imageUrl": "https://uavaustin.org/assets/img/uava_logo_two_tone_dark.png",
    "details": [
      "Improved accuracy of the color classification component of our competition plane",
      "Used HSV instead of RBG color model to make a 3-D coordinate system",
      "Created cubes for various colors and checked whether input color was contained in cubes"
    ],
    "expandedDetails": "I joined the image recognition team of the Unmanned Aerial Vehicle Austin team in the Spring of 2019 to increase my proficiency with Python. Prior to the this, our software used the distance formula to classify colors. This made the color classification system because, for instance, it would classify both pink and purple as red because they were equidistant from \"true\" red, even though they were neither red. I improved this by converting input colors to the HSV system, and setting up a 3-D coordinate system with Hue, Saturation, and Vibrance on the axes. I then made 'Color Cubes' which were areas in the 3-D coordinate space which corresponded to different colors."
  },
  {
    "key": 4,
    "size": "normal",
    "title": "This website",
    "date": "Summer 2019",
    "language": ["ReactJS", "#00d8ff"],
    "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/React-icon.svg/640px-React-icon.svg.png",
    "githubUrl": "https://github.com/kadhirumasankar/kadhirumasankar.github.io",
    "details": [
      "Made entirely from scratch using ReactJS",
      "Implemented SCSS in some places",
      "Extensively used Grid and Flexbox"
    ],
    "expandedDetails": "I stayed in Austin over the summer to help the Texas Rocket Engineering Lab with some work, and since I had recently learned React, I wanted to use that knowledge to make a website to showcase my projects. I also learned Grid and Flexbox to help me design the website."
  },
  {
    "key": 5,
    "size": "normal",
    "title": "Parachute Drift Model for TREL",
    "date": "Fall 2019",
    "language": ["MATLAB", "#842613"],
    "imageUrl": "https://i.imgur.com/Auw8L43.png",
    "githubUrl": "https://gist.github.com/kadhirumasankar/43e64613d691f331b2f8273c45dedbd9",
    "details": [
      "Used the Monte Carlo simulation to predict drift area for the Texas Rocket Engineering Lab rocket after the parachutes are deployed"
    ],
    "expandedDetails": "In Fall 2019, I was made the Responsible Engineer of a team tasked with making a computational model in MATLAB to predict the range that the TREL rocket would drift after its parachutes were deployed. We used the Monte Carlo simulation to approximate the unpredictable nature of the rocket due to random wind conditions. The model took atmospheric conditions into account, and the model was ensured to be versatile and work with different variable values."
  },
  {
    "key": 6,
    "size": "normal",
    "title": "Manual Image Rec UI for UAVA",
    "date": "Spring 2019 - Spring 2020",
    "language": ["ReactJS", "#00d8ff"],
    "imageUrl": "https://i.imgur.com/Afkwqf3.gif",
    "githubUrl": "https://github.com/uavaustin/manual-image-rec",
    "details": [
      "Using ReactJS and Semantic UI React to develop the Manual Image Recognition UI for competition"
    ],
    "expandedDetails": "In Spring 2019, I was tasked to use my knowledge with web development to make a manual image recognition interface that would be used at competition. I also had to learn React to make this interface. The interface would need to have an Explorer page which would show pictures taken by the flight camera, where the user could select an image, and a Classifier page where the user would be able to select targets and send them to the our automatic object classifier model and then to the competition server."
  },
  {
    "key": 7,
    "size": "small",
    "title": "Junior Year",
    "date": "Fall 2019 - Spring 2020",
    "language": ["UT Austin", "#bb5826"],
    "imageUrl": "https://upload.wikimedia.org/wikipedia/en/thumb/e/e1/University_of_Texas_at_Austin_seal.svg/1200px-University_of_Texas_at_Austin_seal.svg.png",
    "additionalText": "Classes taken:",
    "details": [
      "Linear Systems Analysis",
      "Feedback Control Systems",
      "Attitude Dynamics",
      "Applied Orbital Mechanics",
      "Flight Dynamics",
      "Compressible Flow",
      "Rocket Engineering Practicum",
      "Electromechanical Systems",
      "Foundations of Management",
      "Foundations of Marketing"
    ]
  },
  {
    "key": 8,
    "size": "normal",
    "title": "Autonomous Sensing & Perception - Synthetic Aperture Radar Automatic Target Recognition",
    "date": "May 2020 - August 2020",
    "language": ["Sandia", "#26abe2"],
    "imageUrl": "https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Sandia_National_Laboratories_logo.svg/1200px-Sandia_National_Laboratories_logo.svg.png",
    "details": [
      "Wrote code for model analysis and data augmentation for Synthetic Aperture Radar Automatic Target Recognition",
      "Gained experience with Python, specifically 'numpy', 'pandas', and 'matplotlib' packages"
    ],
    "expandedDetails": "I was made part of the Synthetic Aperture Radar Automatic Target Recognition team to increase my knowledge of Convolutional Neural Networks and proficiency with Python. I added functionality to Python code that was used to analyze the performance of templates on SAR chips. I also helped data augmentation by writing functions that would randomly obscure parts of the target’s mask on SAR chips."
  },
  {
    "key": 9,
    "size": "normal",
    "title": "Autonomy for Hypersonics - Object Tracking",
    "date": "May 2020 - August 2020",
    "language": ["Sandia", "#26abe2"],
    "imageUrl": "https://i.imgur.com/b4bzlMW.png",
    "details": [
      "Created a ROS (Robot Operation System) package locate and return the coordinates of objects of interest using a depth camera and YOLOv4 (You Only Look Once object detection system)",
      "Gained experience with ROS, Python, using Tensorflow for object detection, and working with depth images"
    ],
    "expandedDetails": "I was assigned to the “Object Tracking” design reference mission, and I created a ROS (Robot Operation System) package which implemented computer vision on a drone in simulation with an Intel RealSense depth camera. I wrote Python code to use YOLOv4 (You Only Look Once object detection system) on the image from the camera to find objects of interest, and then found the centroid of the object, superimposed the centroid on the depth image from the camera, and used this information to find the vector to the object in the inertial frame. Through this project, I gained experience with ROS, Gazebo 3D simulation environment, and YOLO (and object detection and deep learning as a whole)."
  },
  {
    "key": 10,
    "size": "normal",
    "title": "\"From Agile Ground to Aerial Navigation: Learning from Learned Hallucination\"",
    "date": "September 2020 - May 2021",
    "language": ["Research", "#6c757d"],
    "imageUrl": "https://i.imgur.com/KArF2nm.jpg",
    "details": [
      "Contributed to a publication as part of the UT Autonomous Systems Group",
      "Implemented code to control a 'Holybro PX4 Vision' drone, publish trajectories, and set up a connection to stream depth images to a ROS commander computer",
      "Publication was accepted for presentation at IROS 2021",
      "Gained more experience with ROS, Python, C++, and working with hardware"
    ],
    "expandedDetails": "I joined Dr. Ufuk Topcu's Autonomous Systems Group in September 2020, and I worked under Alexander Nettekoven and with members of the Learning Agents Research Group on this project. I was tasked with first implementing a geometric controller on a drone in simulation and writing code to publish trajectories to the drone. Afterwards, I was tasked with porting this code to a physical drone, testing it, and setting up a stream between the drone and a ROS commander desktop to relay depth images. This was my first experience with working on hardware, and I learned a lot about the differences between working in simulation and on hardware. This paper was published at IROS 2021."
  },
  {
    "key": 11,
    "size": "small",
    "title": "Senior Year",
    "date": "Fall 2020 - Spring 2021",
    "language": ["UT Austin", "#bb5826"],
    "imageUrl": "https://i.imgur.com/ahQpyCu.jpg",
    "additionalText": "Graduated with my Bachelor of Science degree in Aerospace Engineering with honors, along with a minor in Business and a certificate in Computational Science. Classes taken in my senior year:",
    "details": [
      "Computational Methods for Structural Analysis",
      "Aerospace Materials Lab",
      "Spacecraft Mission Design",
      "Aircraft Propulsion",
      "Foundations of Finance",
      "Foundations of Business Law"
    ]
  },
  {
    "key": 12,
    "size": "small",
    "title": "Autonomy for Hypersonics - LQR Controller",
    "date": "October 2020 - *",
    "language": ["Sandia", "#26abe2"],
    "imageUrl": "https://autonomy.sandia.gov/_assets/images/autonomy_logo.png",
    "details": [
      "Creating a ROS (Robot Operation System) package to implement a Linear Quadratic Regulator controller on a drone",
      "After getting the package to work on a quadcopter in simulation, I am currently working on implementing this on a physical hexacopter",
      "Due to information about the project being Official Use Only, further information may be provided by contacting me officially."
    ]
  }
]
